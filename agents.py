# agents.py
from openai import OpenAI
from zhipuai import ZhipuAI
from pydantic import BaseModel, Field
from config import API_KEYS, GAME_CONFIG, MODEL_CONFIG
from personality_traits import PERSONALITY_PROMPTS
import datetime
import time
import json

# æŠŠå…¬ç”¨çš„æè¿°æå–åˆ°ä¸€ä¸ªå˜é‡é‡Œ
COMMON_REASONING_DESC = "æ€è€ƒè¿‡ç¨‹ï¼šéœ€è¦è¾“å‡ºå¾—åˆ° output çš„å®Œæ•´æ€è€ƒé“¾è·¯ã€‚"

# Pydanticæ¨¡å‹å®šä¹‰
class ContributionDecision(BaseModel):
    reasoning: str = Field(
        ...,
        description=COMMON_REASONING_DESC
    )
    output: int = Field(
        ...,
        ge=0,
        description="æœ¬è½®æŠ•å…¥é‡‘é¢ï¼Œå¿…é¡»æ˜¯ 0 åˆ°å½“å‰æ€»é‡‘é¢ä¹‹é—´çš„æ•´æ•°"
    )

class StrategyUpdate(BaseModel):
    reasoning: str = Field(
        ...,
        description=COMMON_REASONING_DESC
    )
    output: str = Field(
        ...,
        description="ç­–ç•¥æ€»ç»“ï¼šç®€è¦æè¿°æ•´ä½“èµ„æºæŠ•å…¥è¶‹åŠ¿åŠæ½œåœ¨é£é™©æˆ–æœºä¼šï¼ˆ1-2å¥ï¼‰"
    )

class BeliefUpdate(BaseModel):
    reasoning: str = Field(
        ...,
        description=COMMON_REASONING_DESC
    )
    output: str = Field(
        ...,
        description="æ›´æ–°åçš„æ€§æ ¼å’Œåˆä½œå€¾å‘æè¿°"
    )
import os
import json
import openai
from openai import OpenAI
from zhipuai import ZhipuAI
from google import genai
from google.genai import types
from config import API_KEYS, MODEL_CONFIG, GAME_CONFIG
from personality_traits import PERSONALITY_PROMPTS
import datetime
import time

class Agent:
    def __init__(self, agent_id, personality_type, is_anchor=False, model=None, provider=None):
        """
        Args:
            agent_id: strï¼Œæ™ºèƒ½ä½“çš„å”¯ä¸€æ ‡è¯†ç¬¦
            personality_type: strï¼Œæ€§æ ¼ç±»å‹ï¼ˆä¾‹å¦‚ï¼šhigh-altruism, medium-altruism, low-altruism, anchorï¼‰
            is_anchor: æ˜¯å¦æ˜¯é”šå®šæ™ºèƒ½ä½“
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
            provider: æ¨¡å‹æä¾›å•†
        """
        self.id = agent_id
        self.name = f"{int(agent_id) + 1}"  # æ™ºèƒ½ä½“åç§°ï¼ŒåŸºäºID+1ç”Ÿæˆ
        self.is_anchor = is_anchor
        self.personality_type = personality_type  # ä¿å­˜æ€§æ ¼ç±»å‹
        self.debug_prompts = False  # é»˜è®¤å…³é—­è°ƒè¯•
        # anchoræ™ºèƒ½ä½“ä¸éœ€è¦prompt
        if not self.is_anchor:
            if personality_type in PERSONALITY_PROMPTS:
                self.system_prompt = PERSONALITY_PROMPTS[personality_type]
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ€§æ ¼ç±»å‹: {personality_type}")
        else:
            self.system_prompt = None
        
        # è®°å¿†å’Œå†å²
        self.history = []   # å­˜å‚¨æ¯è½®çš„åŸºæœ¬æ•°æ®
        self.belief_memory = []   # ä¿¡å¿µè®°å¿†ï¼šæ¯è½®æ›´æ–°ï¼Œå­˜å‚¨å¯¹è‡ªèº«èº«ä»½/é£æ ¼çš„å®è§‚åæ€
        self.llm_interactions = []  # LLMäº¤äº’è®°å½•ï¼šå­˜å‚¨æ¯æ¬¡AIäº¤äº’çš„å®Œæ•´è¾“å…¥è¾“å‡º
        self.reasoning = []  # ç”¨äºå­˜å‚¨æ¯è½®reasoningç­‰çŸ­æœŸè®°å¿†ï¼Œæ›¿ä»£short_term_memory
        self.current_endowment = GAME_CONFIG["endowment"]  # å½“å‰ç¦€èµ‹
        self.current_total_money = GAME_CONFIG["endowment"]  # å½“å‰æ€»é‡‘é¢ï¼ˆåˆå§‹ç¦€èµ‹ + ç´¯è®¡æ”¶ç›Šï¼‰
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„æ¨¡å‹
        self.provider = provider or MODEL_CONFIG["provider"]
        self.model = model or MODEL_CONFIG["model"]
        
        if self.provider == "openai":
            # openai.api_key = API_KEYS["openai"]
            self.client = OpenAI(api_key=API_KEYS["openai"])
        elif self.provider == "zhipuai":
            self.client = ZhipuAI(api_key=API_KEYS["zhipuai"])
        elif self.provider == "gemini":
            # ä½¿ç”¨æ–°çš„Google GenAI SDK
            self.client = genai.Client(api_key=API_KEYS["gemini"])
        elif self.provider == "deepseek":
            # DeepSeekä½¿ç”¨OpenAIå…¼å®¹çš„API
            self.client = OpenAI(
                api_key=API_KEYS["deepseek"],
                base_url="https://api.deepseek.com"
            )

    def _call_llm(self, messages, debug_label="", structured_output=None): 
        # è®°å½•äº¤äº’å¼€å§‹æ—¶é—´
        start_time = datetime.datetime.now()
        
        # æ·»åŠ è°ƒè¯•è¾“å‡º
        if self.debug_prompts:
            try:
                print(f"\n{'='*80}")
                print(f"ã€Agent {self.name} - {self.personality_type} - {self.provider}/{self.model}ã€‘{debug_label}")
                print(f"{'='*80}")
                for i, msg in enumerate(messages):
                    role_name = "ç³»ç»Ÿæ¶ˆæ¯" if msg["role"] == "system" else "ç”¨æˆ·æ¶ˆæ¯"
                    print(f"\nã€{role_name}ã€‘")
                    print(f"{msg['content']}")
                if structured_output:
                    print(f"\nã€ç»“æ„åŒ–è¾“å‡ºç±»å‹ã€‘: {structured_output.__name__}")
                print(f"{'='*80}\n")
            except Exception as debug_error:
                print(f"è°ƒè¯•è¾“å‡ºé”™è¯¯: {debug_error}")
        
        try:
            # LLMè‡ªåŠ¨é‡è¯•æœºåˆ¶
            max_retry = 10
            retry_count = 0
            while True:
                try:
                    if self.provider == "openai":
                        if structured_output:
                            params = {
                                "model": self.model,
                                "input": messages,
                                "text_format": structured_output
                            }
                            response = self.client.responses.parse(**params)
                            parsed_response = response.output_parsed
                            if hasattr(parsed_response, "reasoning") and hasattr(parsed_response, "output"):
                                reasoning = parsed_response.reasoning
                                output = parsed_response.output
                                # æå–estimated_others_avg_ratioå’Œoutput_ratioï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                                estimated_others_avg_ratio = getattr(parsed_response, "estimated_others_avg_ratio", None)
                                output_ratio = getattr(parsed_response, "output_ratio", None)
                                if isinstance(output, (int, float)):
                                    response_content = str(output)
                                else:
                                    response_content = output
                            else:
                                reasoning = None
                                estimated_others_avg_ratio = None
                                output_ratio = None
                                response_content = str(parsed_response)
                        else:
                            params = {
                                "model": self.model,
                                "input": messages
                            }
                            response = self.client.responses.create(**params)
                            raw_response = response.output_text
                            response_content = raw_response
                            reasoning = None
                            estimated_others_avg_ratio = None
                            output_ratio = None
                    elif self.provider == "gemini":
                        # ä½¿ç”¨æ–°çš„Google GenAI SDKè°ƒç”¨ï¼Œæ”¯æŒsystem instruction
                        system_instruction = ""
                        user_content = ""
                        
                        for msg in messages:
                            if msg["role"] == "system":
                                system_instruction += msg["content"] + "\n\n"
                            elif msg["role"] == "user":
                                user_content += msg["content"] + "\n\n"
                            elif msg["role"] == "assistant":
                                user_content += f"[Previous response: {msg['content']}]\n\n"
                        
                        # æ„å»ºGenerateContentConfig
                        config_kwargs = {
                            "thinking_config": types.ThinkingConfig(thinking_budget=0)
                        }
                        
                        # å¦‚æœæœ‰system instructionï¼Œæ·»åŠ åˆ°config
                        if system_instruction.strip():
                            config_kwargs["system_instruction"] = system_instruction.strip()
                        
                        # å¦‚æœæœ‰structured_outputè¦æ±‚ï¼Œæ·»åŠ JSON schema
                        if structured_output:
                            config_kwargs["response_mime_type"] = "application/json"
                            config_kwargs["response_schema"] = structured_output
                        
                        # åˆ›å»ºconfigå¯¹è±¡
                        config = types.GenerateContentConfig(**config_kwargs)
                        
                        # è°ƒç”¨Gemini API
                        response = self.client.models.generate_content(
                            model=self.model,
                            contents=user_content.strip(),
                            config=config
                        )
                        
                        # å¤„ç†å“åº”
                        if structured_output:
                            # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
                            parsed_response = response.parsed
                            if hasattr(parsed_response, "reasoning") and hasattr(parsed_response, "output"):
                                reasoning = parsed_response.reasoning
                                output = parsed_response.output
                                # æå–estimated_others_avg_ratioå’Œoutput_ratioï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                                estimated_others_avg_ratio = getattr(parsed_response, "estimated_others_avg_ratio", None)
                                output_ratio = getattr(parsed_response, "output_ratio", None)
                                if isinstance(output, (int, float)):
                                    response_content = str(output)
                                else:
                                    response_content = output
                            else:
                                reasoning = None
                                estimated_others_avg_ratio = None
                                output_ratio = None
                                response_content = str(parsed_response)
                        else:
                            # éç»“æ„åŒ–è¾“å‡º
                            raw_response = response.text.strip()
                            response_content = raw_response
                            reasoning = None
                            estimated_others_avg_ratio = None
                            output_ratio = None
                    elif self.provider == "deepseek":
                        # DeepSeekä½¿ç”¨OpenAIå…¼å®¹API + JSON mode
                        if structured_output:
                            # DeepSeekéœ€è¦åœ¨system promptä¸­è¯´æ˜JSONæ ¼å¼
                            # æ·»åŠ JSONè¾“å‡ºæ ¼å¼è¯´æ˜åˆ°system message
                            schema_instruction = f"\n\nPlease output your response in the following JSON format:\n{json.dumps(structured_output.model_json_schema(), indent=2)}\n\nIMPORTANT: Output ONLY valid JSON, no additional text."
                            
                            # ä¿®æ”¹messages,å°†schemaè¯´æ˜åŠ å…¥system prompt
                            modified_messages = messages.copy()
                            if modified_messages and modified_messages[0]["role"] == "system":
                                modified_messages[0] = {
                                    "role": "system",
                                    "content": modified_messages[0]["content"] + schema_instruction
                                }
                            else:
                                modified_messages.insert(0, {
                                    "role": "system", 
                                    "content": schema_instruction
                                })
                            
                            # ä½¿ç”¨JSON mode (ç®€åŒ–æ ¼å¼)
                            params = {
                                "model": self.model,
                                "messages": modified_messages,
                                "response_format": {
                                    "type": "json_object"  # DeepSeekä½¿ç”¨ç®€åŒ–çš„JSON mode
                                }
                            }
                            
                            response = self.client.chat.completions.create(**params)
                            raw_json = response.choices[0].message.content.strip()
                            
                            # è§£æJSONä¸ºPydanticå¯¹è±¡ (jsonå·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥)
                            parsed_data = json.loads(raw_json)
                            parsed_response = structured_output(**parsed_data)
                            
                            if hasattr(parsed_response, "reasoning") and hasattr(parsed_response, "output"):
                                reasoning = parsed_response.reasoning
                                output = parsed_response.output
                                estimated_others_avg_ratio = getattr(parsed_response, "estimated_others_avg_ratio", None)
                                output_ratio = getattr(parsed_response, "output_ratio", None)
                                if isinstance(output, (int, float)):
                                    response_content = str(output)
                                else:
                                    response_content = output
                            else:
                                reasoning = None
                                estimated_others_avg_ratio = None
                                output_ratio = None
                                response_content = str(parsed_response)
                        else:
                            # éç»“æ„åŒ–è¾“å‡º
                            params = {
                                "model": self.model,
                                "messages": messages
                            }
                            response = self.client.chat.completions.create(**params)
                            raw_response = response.choices[0].message.content.strip()
                            response_content = raw_response
                            reasoning = None
                            estimated_others_avg_ratio = None
                            output_ratio = None
                    else:
                        raise ValueError(f"Unsupported provider: {self.provider}")
                    # æ£€æŸ¥æ˜¯å¦ä¸ºè¿æ¥å¤±è´¥
                    if isinstance(response_content, str) and response_content.startswith("LLMè°ƒç”¨å¤±è´¥: Connection error"):
                        raise RuntimeError("LLMè°ƒç”¨å¤±è´¥: Connection error")
                    break
                except Exception as e:
                    retry_count += 1
                    if retry_count >= max_retry:
                        raise RuntimeError(f"LLMè°ƒç”¨å¤±è´¥: Connection error, å·²é‡è¯•{max_retry}æ¬¡ä»æœªæˆåŠŸã€‚æœ€åé”™è¯¯: {e}")
                    time.sleep(1)
        except Exception as e:
            raw_response = f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"
            response_content = raw_response
            reasoning = None
            estimated_others_avg_ratio = None
            output_ratio = None
        
        # è®°å½•äº¤äº’ç»“æŸæ—¶é—´
        end_time = datetime.datetime.now()
        
        # è®°å½•å®Œæ•´çš„äº¤äº’ä¿¡æ¯
        interaction_record = {
            "timestamp": start_time.isoformat(),
            "debug_label": debug_label,
            "duration_seconds": (end_time - start_time).total_seconds(),
            "model": self.model,
            "provider": self.provider,
            "input": {
                "messages": messages
            },
            "output": {
                # "raw_response": raw_response,
                "content": response_content,
                "reasoning": reasoning if reasoning else None,
                "estimated_others_avg_ratio": estimated_others_avg_ratio if estimated_others_avg_ratio else None,
                "output_ratio": output_ratio if output_ratio else None,
                "structured_output_type": structured_output.__name__ if structured_output else None,
                "status": "success" if not response_content.startswith("LLMè°ƒç”¨å¤±è´¥") else "error"
            }
        }
        
        # æ·»åŠ åˆ°æ™ºèƒ½ä½“çš„äº¤äº’å†å²
        self.llm_interactions.append(interaction_record)
        # è‡ªåŠ¨å†™å…¥reasoningè®°å¿†ï¼ˆåªå­˜å­—ç¬¦ä¸²ï¼‰
        if reasoning:
            self.reasoning.append(reasoning)
        
        # æ·»åŠ è°ƒè¯•è¾“å‡ºï¼šæ˜¾ç¤ºLLMè¿”å›ç»“æœ
        if self.debug_prompts:
            try:
                print(f"\n{'ğŸ¤–'*40}")
                print(f"ã€Agent {self.name} çš„ LLM è¿”å›ç»“æœã€‘")
                print(f"{'ğŸ¤–'*40}")
                print(f"æ¨¡å‹: {self.provider}/{self.model}")
                print(f"è€—æ—¶: {(end_time - start_time).total_seconds():.2f}ç§’")
                if structured_output:
                    print(f"\nğŸ“Š ç»“æ„åŒ–è¾“å‡º:")
                    if estimated_others_avg_ratio is not None:
                        print(f"  â€¢ ä¼°ç®—ä»–äººå¹³å‡æŠ•å…¥æ¯”ä¾‹: {estimated_others_avg_ratio}%")
                    if output_ratio is not None:
                        print(f"  â€¢ è‡ªå·±æŠ•å…¥æ¯”ä¾‹: {output_ratio}%")
                    print(f"  â€¢ æŠ•å…¥é‡‘é¢: {response_content}")
                    if reasoning:
                        print(f"  â€¢ æ¨ç†è¿‡ç¨‹: {reasoning[:200]}..." if len(reasoning) > 200 else f"  â€¢ æ¨ç†è¿‡ç¨‹: {reasoning}")
                else:
                    print(f"\nğŸ“ åŸå§‹è¾“å‡º: {response_content}")
                print(f"{'ğŸ¤–'*40}\n")
            except Exception as debug_error:
                print(f"è°ƒè¯•è¾“å‡ºé”™è¯¯: {debug_error}")
        
        return response_content

    def decide_contribution(self, round_number, r, num_players, all_history=None, mode="public", avg_contrib_ratio=None):
        """å†³å®šæœ¬è½®çš„æŠ•å…¥é‡‘é¢
        
        Args:
            round_number: å½“å‰è½®æ•°
            r: å…¬å…±æ± å€æ•°
            num_players: ç©å®¶æ€»æ•°
            all_history: æ‰€æœ‰ç©å®¶çš„å†å²è®°å½•
            mode: ä¿¡æ¯æ¨¡å¼ ("public" æˆ– "anonymous")
            avg_contrib_ratio: åŒ¿åæ¨¡å¼ä¸‹ä¸Šä¸€è½®çš„å¹³å‡è´¡çŒ®æ¯”ä¾‹
        """
        # é”šå®šæ™ºèƒ½ä½“ç›´æ¥è¿”å›å…¨éƒ¨å½“å‰é‡‘é¢ï¼ˆ100%æŠ•å…¥ï¼‰
        if self.is_anchor:
            return self.current_total_money

        # æ„å»ºæç¤ºä¿¡æ¯
        # æ ¹æ®æŒ‡å¯¼è¯­ç±»å‹ç¡®å®šè½®æ•°æè¿°
        instruction_type = GAME_CONFIG.get("instruction_type", "certain")
        total_rounds = GAME_CONFIG.get("rounds", 10)
        
        if instruction_type == "certain":
            round_info = f"å½“å‰ç¬¬ {round_number} è½®ï¼Œæ€»å…±æœ‰ {total_rounds} è½®"
        else:  # uncertain
            round_info = f"å½“å‰ç¬¬ {round_number} è½®ï¼Œæ¸¸æˆå°†æŒç»­è‹¥å¹²è½®ï¼Œå¯èƒ½åœ¨ä»»æ„ä¸€è½®ç»“æŸ"
        
        base_prompt = f"""ä½ æ˜¯ç©å®¶"{self.name}"ã€‚

        æ¸¸æˆè§„åˆ™ï¼š
        - {round_info}
        - ä½ æœ‰ {self.current_total_money} æšä»£å¸å¯æŠ•å…¥å…¬å…±æ± ï¼ˆåŒ…æ‹¬åˆå§‹ç¦€èµ‹å’Œä¹‹å‰çš„æ”¶ç›Šï¼‰ï¼Œä½ çš„æŠ•å…¥èŒƒå›´ï¼š0 åˆ° {self.current_total_money}
        - æœ¬è½®å…¬å…±æ± ç”±æ‰€æœ‰ç©å®¶çš„æŠ•å…¥ç´¯ç§¯å½¢æˆ
        - å…¬å…±æ± æ€»é¢ Ã— {r} åï¼Œå°†å¹³å‡åˆ†é…ç»™æ‰€æœ‰ç©å®¶"""

        # æ ¹æ®æ¨¡å¼æ·»åŠ å†å²ä¿¡æ¯
        if round_number > 1:
            base_prompt += f"\n\nå†å²æŠ•å…¥è®°å½•ï¼š"
            
            # æ·»åŠ è‡ªå·±çš„å†å²æŠ•å…¥
            base_prompt += f"\nä½ çš„å†å²æŠ•å…¥ï¼š"
            for r in range(1, round_number):
                if r <= len(self.history):
                    history_entry = self.history[r-1]
                    my_contrib = history_entry['contribution']
                    my_payoff = history_entry['payoff']
                    my_total_before = history_entry.get('total_money_before_round', my_contrib + my_payoff)
                    my_ratio = (my_contrib / my_total_before * 100) if my_total_before > 0 else 0
                    base_prompt += f"\n  ç¬¬{r}è½®: æŠ•å…¥{my_contrib}/{my_total_before} ({my_ratio:.1f}%), æ”¶ç›Š{my_payoff:.1f}"
            
            # åŒ¿åæ¨¡å¼ä¸‹ï¼ŒåŠ å…¥ä¸Šä¸€è½®å¹³å‡è´¡çŒ®æ¯”ä¾‹
            # if mode == "anonymous" and avg_contrib_ratio is not None:
            #     base_prompt += f"\nä¸Šä¸€è½®æ‰€æœ‰ç©å®¶å¹³å‡è´¡çŒ®æ¯”ä¾‹ä¸º: {avg_contrib_ratio:.1%}"
            
            # æ ¹æ®æ¨¡å¼æ·»åŠ å…¶ä»–ç©å®¶å†å²ä¿¡æ¯
            if all_history and mode == "public":
                # å…¬å¼€æ¨¡å¼ï¼šæ˜¾ç¤ºæ‰€æœ‰ç©å®¶æ‰€æœ‰è½®æ¬¡çš„è´¡çŒ®
                base_prompt += f"\n\nå…¶ä»–ç©å®¶å†å²æŠ•å…¥ï¼š"
                for player_id, player_data in all_history.items():
                    if player_id != self.id:
                        player_history = player_data.get('history', player_data)  # å…¼å®¹æ—§æ ¼å¼
                        base_prompt += f"\nç©å®¶{player_id}: "
                        for r in range(1, round_number):
                            if r <= len(player_history):
                                history_entry = player_history[r-1]
                                contrib = history_entry['contribution']
                                # å°è¯•è·å–æŠ•å…¥èŒƒå›´ä¿¡æ¯
                                if isinstance(history_entry, dict) and 'total_money_before_round' in history_entry:
                                    total_before = history_entry['total_money_before_round']
                                    ratio = (contrib / total_before * 100) if total_before > 0 else 0
                                    base_prompt += f"ç¬¬{r}è½®:{contrib}/{total_before}({ratio:.1f}%) "
                                else:
                                    base_prompt += f"ç¬¬{r}è½®:{contrib} "
            elif all_history and mode == "anonymous":
                # åŒ¿åæ¨¡å¼ï¼šæ˜¾ç¤ºæ¯è½®ä»–äººå¹³å‡è´¡çŒ®æ¯”ä¾‹
                base_prompt += f"\n\nå…¶ä»–ç©å®¶æ±‡æ€»ä¿¡æ¯ï¼š"
                for r in range(1, round_number):
                    round_total = 0
                    round_init_total = 0
                    round_count = 0
                    for player_id, player_data in all_history.items():
                        if player_id != self.id:
                            player_history = player_data.get('history', player_data)  # å…¼å®¹æ—§æ ¼å¼
                            if r <= len(player_history):
                                contrib = player_history[r-1]['contribution']
                                # ä¼˜å…ˆç”¨init_amountï¼Œæ²¡æœ‰åˆ™ç”¨total_money_before_roundï¼Œå†æ²¡æœ‰ç”¨endowment
                                init_amt = player_history[r-1].get('init_amount', None)
                                if init_amt is None:
                                    init_amt = player_history[r-1].get('total_money_before_round', None)
                                if init_amt is None and r == 1:
                                    init_amt = GAME_CONFIG.get('endowment', 10)
                                round_total += contrib
                                if init_amt is not None and init_amt > 0:
                                    round_init_total += init_amt
                                    round_count += 1
                    if round_count > 0 and round_init_total > 0:
                        avg_contrib_ratio = (round_total / round_init_total) * 100
                        base_prompt += f"\n  ç¬¬{r}è½®: ä»–äººå¹³å‡è´¡çŒ®æ¯”ä¾‹{avg_contrib_ratio:.1f}%"
                    else:
                        base_prompt += f"\n  ç¬¬{r}è½®: ä»–äººå¹³å‡è´¡çŒ®æ¯”ä¾‹--%"
        # æ·»åŠ ç»“æ„åŒ–è¾“å‡ºè¯´æ˜
        base_prompt += f"\n\nè¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š"
        base_prompt += f"\n1. ä¼°è®¡å…¶ä»–ç©å®¶æœ¬è½®çš„å¹³å‡æŠ•å…¥æ¯”ä¾‹ï¼ˆ0-100%ä¹‹é—´ï¼ŒåŸºäºå†å²è¡¨ç°å’Œå½“å‰æƒ…å†µï¼‰"
        base_prompt += f"\n2. å†³å®šä½ æœ¬è½®çš„å…·ä½“æŠ•å…¥é‡‘é¢ï¼ˆå¿…é¡»åœ¨0â€“{self.current_total_money}ä¹‹é—´çš„æ•´æ•°ï¼‰"
        base_prompt += f"\n3. è¯´æ˜ä½ çš„å®Œæ•´å†³ç­–ç†ç”±ï¼ˆåŒ…æ‹¬ï¼šä½ å¦‚ä½•è®¤çŸ¥å…¶ä»–ç©å®¶çš„è¡Œä¸ºã€ä½ è€ƒè™‘çš„è¾¹é™…æ”¶ç›Šå’Œé£é™©ã€ä»¥åŠä½ çš„åšå¼ˆç­–ç•¥ï¼‰"
        
        # ä½¿ç”¨å½“å‰çš„ç³»ç»Ÿæç¤ºï¼ˆå¯èƒ½å·²è¢«ä¿¡å¿µè®°å¿†æ›´æ–°ï¼‰
        current_system_prompt = self.get_current_system_prompt()
        
        messages = [
            {"role": "system", "content": current_system_prompt},
            {"role": "user", "content": base_prompt}
        ]
        
        # åˆ›å»ºç”¨äºç»“æ„åŒ–è¾“å‡ºçš„åŠ¨æ€æ¨¡å‹
        class DynamicContributionDecision(BaseModel):
            estimated_others_avg_ratio: float = Field(
                ...,
                ge=0,
                le=100,
                description=f"ä¼°è®¡å…¶ä»–ç©å®¶æœ¬è½®çš„å¹³å‡æŠ•å…¥æ¯”ä¾‹ï¼ˆ0-100ä¹‹é—´çš„ç™¾åˆ†æ¯”æ•°å€¼ï¼Œä¾‹å¦‚50è¡¨ç¤º50%ï¼‰"
            )
            output: int = Field(
                ...,
                ge=0,
                le=self.current_total_money,
                description=f"æœ¬è½®æŠ•å…¥é‡‘é¢ï¼Œå¿…é¡»æ˜¯ 0â€“{self.current_total_money} ä¹‹é—´çš„æ•´æ•°"
            )
            output_ratio: float = Field(
                ...,
                ge=0,
                le=100,
                description=f"æœ¬è½®æŠ•å…¥æ¯”ä¾‹ï¼ˆ0-100ä¹‹é—´çš„ç™¾åˆ†æ¯”æ•°å€¼ï¼Œåº”è¯¥ç­‰äº output/{self.current_total_money}*100ï¼‰"
            )
            reasoning: str = Field(
                ...,
                description="å®Œæ•´å†³ç­–ç†ç”±ï¼šå…ˆè¯´æ˜ä½ å¦‚ä½•è®¤çŸ¥å…¶ä»–ç©å®¶ï¼ˆä¸ºä»€ä¹ˆä¼°è®¡ä»–ä»¬ä¼šè¿™æ ·æŠ•å…¥ï¼‰ï¼Œå†è§£é‡Šä½ è‡ªå·±çš„å†³ç­–é€»è¾‘ï¼ˆè€ƒè™‘è¾¹é™…æ”¶ç›Šã€é£é™©ä»¥åŠåšå¼ˆç­–ç•¥ï¼‰"
            )
        
        # è°ƒç”¨LLMï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
        if self.provider in ["openai", "gemini", "deepseek"]:
            # OpenAI, Geminiå’ŒDeepSeekéƒ½æ”¯æŒç»“æ„åŒ–è¾“å‡º
            answer = self._call_llm(messages, debug_label="å†³ç­–é˜¶æ®µ", structured_output=DynamicContributionDecision)
        else:
            # å…¶ä»–æ¨¡å‹ä½¿ç”¨éç»“æ„åŒ–è¾“å‡º
            answer = self._call_llm(messages, debug_label="å†³ç­–é˜¶æ®µ")
            
        try:
            value = int(answer)
        except ValueError:
            value = 0
        return max(0, min(self.current_total_money, value))

    def get_current_system_prompt(self):
        """è·å–å½“å‰çš„ç³»ç»Ÿæç¤ºï¼ˆå¯èƒ½å·²è¢«ä¿¡å¿µè®°å¿†æ›´æ–°ï¼‰"""
        if self.is_anchor:
            return "ä½ æ˜¯é”šå®šæ™ºèƒ½ä½“ï¼Œæ¯è½®è‡ªåŠ¨å…¨éƒ¨æŠ•å…¥ï¼Œæ— éœ€æ¨ç†ã€‚"
        if self.belief_memory:
            latest_belief = self.belief_memory[-1]
            if 'new_system_prompt' in latest_belief:
                return latest_belief['new_system_prompt']
            elif 'updated_system_prompt' in latest_belief:
                return latest_belief['updated_system_prompt']
        # å…œåº•ï¼šå¦‚æœsystem_promptä¸ºNoneï¼Œè¿”å›neutralæˆ–é»˜è®¤æç¤º
        base_prompt = self.system_prompt if self.system_prompt else PERSONALITY_PROMPTS.get("neutral", "ä½ æ˜¯ä¸€åç©å®¶ã€‚")
        return f"{base_prompt} ä½ æ­£åœ¨å‚ä¸å…¬å…±å“åšå¼ˆã€‚è¯·æ ¹æ®ä½ çš„æ€§æ ¼ç‰¹å¾å’Œåœºæ™¯åšå‡ºåˆç†å†³ç­–ã€‚"

    def get_latest_belief(self):
        """è·å–æœ€æ–°çš„ä¿¡å¿µè®°å¿†"""
        if not self.belief_memory:
            return None
        return f"å½“å‰èº«ä»½çŠ¶æ€: {self.belief_memory[-1]['updated_personality']}"

    def update_total_money(self, new_total):
        """æ›´æ–°å½“å‰æ€»é‡‘é¢"""
        self.current_total_money = new_total

    def record_memory(self, round_number, event_type, content):
        """è®°å½•äº‹ä»¶åˆ°è®°å¿†æ—¥å¿—ï¼ˆå·²è¢«æ–°çš„è®°å¿†ç³»ç»Ÿæ›¿ä»£ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
        
        Args:
            round_number: å½“å‰å›åˆæ•°
            event_type: äº‹ä»¶ç±»å‹ï¼ˆ'contribution', 'discussion', 'outcome'ç­‰ï¼‰
            content: äº‹ä»¶å†…å®¹
        """
        # æ–°çš„è®°å¿†ç³»ç»Ÿä¸å†ä½¿ç”¨æ­¤æ–¹æ³•ï¼Œä½†ä¿ç•™ä»¥ç¡®ä¿å‘åå…¼å®¹
        pass

    def record_round_data(self, round_num, contribution, group_total, payoff, total_money_before_round=None):
        """
        è®°å½•æ¯è½®çš„åŸºæœ¬æ•°æ®
        Args:
            round_num: å½“å‰è½®æ¬¡
            contribution: ä¸ªäººè´¡çŒ®
            group_total: ç»„æ€»è´¡çŒ®
            payoff: æ”¶ç›Š
            total_money_before_round: æœ¬è½®å¼€å§‹å‰çš„æ€»é‡‘é¢ï¼ˆæŠ•å…¥èŒƒå›´ï¼‰
        """
        # å…ˆè®°å½•æœ¬è½®å¼€å§‹å‰çš„é‡‘é¢
        round_data = {
            'id': self.id,
            'round': round_num,
            'contribution': int(round(contribution)) if self.is_anchor else contribution,
            'group_total': group_total,
            'payoff': payoff,
            'total_money_before_round': int(round(total_money_before_round)) if self.is_anchor and total_money_before_round is not None else total_money_before_round if total_money_before_round is not None else self.current_total_money
        }
        self.history.append(round_data)
        # å†ç»“ç®—æœ¬è½®åçš„é‡‘é¢
        if self.is_anchor:
            self.current_total_money = int(round((total_money_before_round if total_money_before_round is not None else self.current_total_money) - contribution + payoff))
        else:
            self.current_total_money = (total_money_before_round if total_money_before_round is not None else self.current_total_money) - contribution + payoff
        return round_data

    def set_debug_mode(self, debug=True):
        """è®¾ç½®æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼ˆpromptå†…å®¹ï¼‰"""
        self.debug_prompts = debug

    def get_current_endowment(self):
        """è·å–å½“å‰æ€»é‡‘é¢ï¼ˆå·²åŒ…å«æ‰€æœ‰æ”¶ç›Šï¼‰"""
        return self.current_total_money

    def update_memory(self, round_number, own_contribution, payoff, reveal_mode, all_history=None):
        """æ›´æ–°æ™ºèƒ½ä½“çš„è®°å¿†ç³»ç»Ÿï¼ˆä»…éanchoræ™ºèƒ½ä½“ï¼‰
        
        Args:
            round_number: å½“å‰å›åˆæ•°
            own_contribution: è‡ªå·±çš„è´¡çŒ®
            payoff: æœ¬è½®æ”¶ç›Š
            reveal_mode: ä¿¡æ¯å…¬å¼€æ¨¡å¼ ("public" æˆ– "anonymous")
            all_history: æ‰€æœ‰ç©å®¶çš„å†å²è®°å½•
        """
        if self.is_anchor:
            return  # anchorä¸æ›´æ–°è®°å¿†
        
        # æ›´æ–°æ€»é‡‘é¢ï¼ˆå–æ•´æ•°ï¼‰
        self.current_total_money = int(round(payoff))
        
        # æ³¨æ„ï¼šç­–ç•¥å’Œä¿¡å¿µæ›´æ–°ç°åœ¨ç”±æ¸¸æˆæ§åˆ¶å™¨ç»Ÿä¸€ç®¡ç†ï¼Œä¸åœ¨è¿™é‡Œè¿›è¡Œ

    def _update_belief_memory(self, round_number, reveal_mode, all_history):
        """æ¯è½®æ›´æ–°ä¿¡å¿µè®°å¿†ï¼Œè¾“å…¥ä¸ºæœ€è¿‘reasoningï¼Œè¾“å‡ºä¸ºæ›´å®è§‚çš„è‡ªæˆ‘åæ€"""
        if self.is_anchor:
            return  # anchorä¸æ›´æ–°ä¿¡å¿µ
        # æ”¶é›†æ‰€æœ‰ reasoningï¼Œå…¨éƒ¨ä¸ºå­—ç¬¦ä¸²
        recent_reasonings = "\n".join(self.reasoning[-3:])  # å–æœ€è¿‘3è½®ï¼Œä¹Ÿå¯è°ƒæ•´ä¸ºå…¨éƒ¨
        
        # æ„å»ºsystem prompt
        current_system = self.get_current_system_prompt()
        system_prompt = f"""{current_system}

ä½ å½“å‰éœ€è¦æ ¹æ®æœ€è¿‘å‡ è½®çš„æ€è€ƒæ‘˜è¦ï¼Œå¯¹ä½ çš„ä¿¡å¿µè¿›è¡Œæ›´æ–°ï¼š
- è¾“å‡ºä¸ºä¸€ä¸ªç®€æ´æ®µè½ï¼Œä¸åŒ…å«æ•°å­—æˆ–è½®æ¬¡ç»†èŠ‚
- æ®µè½ä¸­ä½“ç°è¡Œä¸ºé£æ ¼ã€ä»·å€¼è§‚ã€è‡ªæˆ‘è®¤çŸ¥
- ä¿æŒæ•´ä½“é£æ ¼è¿è´¯"""
        
        # æ„å»ºuser prompt
        user_prompt = f"""ä»¥ä¸‹æ˜¯æœ€è¿‘å‡ è½®çš„æ€è€ƒæ‘˜è¦ï¼š
{recent_reasonings}"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        # è°ƒç”¨ LLMï¼Œç›´æ¥è·å–æ–‡æœ¬è¾“å‡ºï¼ˆä¸éœ€è¦reasoningï¼‰
        updated_personality = self._call_llm(messages, debug_label="ä¿¡å¿µæ›´æ–°")
        
        # è®°å½•ä¿¡å¿µè®°å¿†
        self.belief_memory.append({
            "round": round_number,
            "updated_personality": updated_personality,
            "prompt": user_prompt
        })
        # ä¿¡å¿µæ›´æ–°åè‡ªåŠ¨æ›´æ–°system_promptï¼Œè‡ªåŠ¨å°†â€œæˆ‘â€æ›¿æ¢ä¸ºâ€œä½ â€
        self.system_prompt = updated_personality.replace("æˆ‘", "ä½ ")

    def make_final_decision(self, initial_endowment, r, num_players):
        """æ¸¸æˆç»“æŸåçš„ä¸€æ¬¡æ€§PGGå†³ç­–
        
        Args:
            initial_endowment: åˆå§‹ç¦€èµ‹ï¼ˆç”¨äºæœ€åçš„ä¸€æ¬¡æ€§æ¸¸æˆï¼‰
            r: å…¬å…±æ± å€æ•°
            num_players: ç©å®¶æ•°é‡
            
        Returns:
            int: æŠ•å…¥é‡‘é¢ï¼ˆ0åˆ°initial_endowmentï¼‰
        """
        if self.is_anchor:
            return initial_endowment

        prompt = f"""ç°åœ¨ä½ é¢ä¸´ä¸€ä¸ªå…¨æ–°çš„ä¸€æ¬¡æ€§å…¬å…±å“åšå¼ˆï¼š

        æ¸¸æˆè§„åˆ™ï¼š
        - å½“å‰æ˜¯ä¸€è½®ç‹¬ç«‹çš„æ–°æ¸¸æˆï¼Œä½ ä¸ {num_players-1} åé™Œç”Ÿç©å®¶è¿›è¡Œä¸€æ¬¡æ€§åšå¼ˆ
        - ä½ æœ‰ {initial_endowment} æšä»£å¸å¯æŠ•å…¥å…¬å…±æ± ï¼ˆåŒ…æ‹¬åˆå§‹ç¦€èµ‹å’Œä¹‹å‰çš„æ”¶ç›Šï¼‰
        - å…¬å…±æ± æ€»é¢ Ã— {r} åå¹³åˆ†ç»™æ‰€æœ‰ç©å®¶
        - ä½ çš„æŠ•å…¥èŒƒå›´ï¼š0 åˆ° {initial_endowment}

        è¯·åŸºäºä½ åœ¨ä¹‹å‰æ¸¸æˆä¸­å½¢æˆçš„ç­–ç•¥å’Œä¿¡å¿µï¼Œå†³å®šåœ¨è¿™ä¸ªä¸€æ¬¡æ€§åšå¼ˆä¸­çš„æŠ•å…¥ã€‚"""

        messages = [
            {"role": "system", "content": self.get_current_system_prompt()},
            {"role": "user", "content": prompt}
        ]
        
        # åˆ›å»ºç”¨äºç»“æ„åŒ–è¾“å‡ºçš„åŠ¨æ€æ¨¡å‹
        class FinalDecision(BaseModel):
            reasoning: str = Field(
                ...,
                description="æ€è€ƒè¿‡ç¨‹ï¼šè§£é‡Šåœ¨æœ€ç»ˆä¸€æ¬¡æ€§å†³ç­–ä¸­è€ƒè™‘çš„å› ç´ "
            )
            output: int = Field(
                ...,
                ge=0,
                le=initial_endowment,
                description=f"æŠ•å…¥é‡‘é¢ï¼Œå¿…é¡»æ˜¯0â€“{initial_endowment}ä¹‹é—´çš„æ•´æ•°"
            )
        
        # è°ƒç”¨LLMï¼Œä½¿ç”¨ç»“æ„åŒ–è¾“å‡º
        if self.provider in ["openai", "gemini", "deepseek"]:
            # OpenAI, Geminiå’ŒDeepSeekéƒ½æ”¯æŒç»“æ„åŒ–è¾“å‡º
            answer = self._call_llm(messages, debug_label="æœ€ç»ˆä¸€æ¬¡æ€§å†³ç­–", structured_output=FinalDecision)
        else:
            # å…¶ä»–æ¨¡å‹ä½¿ç”¨éç»“æ„åŒ–è¾“å‡º
            answer = self._call_llm(messages, debug_label="æœ€ç»ˆä¸€æ¬¡æ€§å†³ç­–")
            
        try:
            value = int(answer)
        except ValueError:
            value = 0
        return max(0, min(initial_endowment, value))

    def _format_recent_rounds_info(self, round_number, reveal_mode, all_history):
        """æ ¼å¼åŒ–æœ€è¿‘2è½®çš„å„ç©å®¶æŠ•å…¥ä¿¡æ¯"""
        info_text = ""
        start_round = max(1, round_number - 1)  # æœ€è¿‘2è½®
        
        # åŒ…æ‹¬å½“å‰è½®æ¬¡åœ¨å†…çš„æœ€è¿‘2è½®
        for r in range(start_round, round_number + 1):
            info_text += f"\nç¬¬{r}è½®æŠ•å…¥æƒ…å†µï¼š"
            
            # æ·»åŠ è‡ªå·±çš„æŠ•å…¥
            if r <= len(self.history):
                history_entry = self.history[r-1]
                my_contrib = history_entry['contribution']
                my_total_before = history_entry.get('total_money_before_round', my_contrib)
                my_ratio = (my_contrib / my_total_before * 100) if my_total_before > 0 else 0
                info_text += f"\n  ä½ : {my_contrib}/{my_total_before}({my_ratio:.1f}%)"
            
            # æ ¹æ®æ¨¡å¼æ·»åŠ å…¶ä»–ç©å®¶ä¿¡æ¯
            if all_history and reveal_mode == "public":
                for player_id, player_data in all_history.items():
                    if player_id != self.id:
                        # å…¼å®¹æ–°æ—§æ•°æ®æ ¼å¼
                        player_history = player_data.get('history', player_data) if isinstance(player_data, dict) else player_data
                        if r <= len(player_history):
                            history_entry = player_history[r-1]
                            contrib = history_entry['contribution']
                            # å°è¯•è·å–æŠ•å…¥èŒƒå›´ä¿¡æ¯
                            if isinstance(history_entry, dict) and 'total_money_before_round' in history_entry:
                                total_before = history_entry['total_money_before_round']
                                ratio = (contrib / total_before * 100) if total_before > 0 else 0
                                info_text += f"\n  ç©å®¶{player_id}: {contrib}/{total_before}(æŠ•å…¥æ¯”ä¾‹ï¼š{ratio:.1f}%)"
                            else:
                                # å¦‚æœæ²¡æœ‰total_money_before_roundä¿¡æ¯ï¼Œåªæ˜¾ç¤ºæŠ•å…¥é‡‘é¢
                                info_text += f"\n  ç©å®¶{player_id}: {contrib}"
            elif all_history:
                # åŒ¿åæ¨¡å¼ï¼šè®¡ç®—å…¶ä»–ç©å®¶å¹³å‡å€¼
                other_contribs = []
                other_totals = []
                for player_id, player_data in all_history.items():
                    if player_id != self.id:
                        # å…¼å®¹æ–°æ—§æ•°æ®æ ¼å¼
                        player_history = player_data.get('history', player_data) if isinstance(player_data, dict) else player_data
                        if r <= len(player_history):
                            history_entry = player_history[r-1]
                            other_contribs.append(history_entry['contribution'])
                            if isinstance(history_entry, dict) and 'total_money_before_round' in history_entry:
                                other_totals.append(history_entry['total_money_before_round'])
                
                if other_contribs:
                    avg_contrib = sum(other_contribs) / len(other_contribs)
                    if other_totals and len(other_totals) == len(other_contribs):
                        avg_total = sum(other_totals) / len(other_totals)
                        avg_ratio = (avg_contrib / avg_total * 100) if avg_total > 0 else 0
                        info_text += f"\n  å…¶ä»–ç©å®¶å¹³å‡: {avg_contrib:.1f}/{avg_total:.1f}({avg_ratio:.1f}%)"
                    else:
                        info_text += f"\n  å…¶ä»–ç©å®¶å¹³å‡: {avg_contrib:.1f}"
        
        return info_text.strip() if info_text else "æš‚æ— å†å²è®°å½•"
